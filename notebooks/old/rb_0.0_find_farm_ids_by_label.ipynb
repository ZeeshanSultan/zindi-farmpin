{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find farm IDs by label\n",
    "\n",
    "Find the Farm IDs present in each label (JFP and JEP)\n",
    "\n",
    "Save a shapefile for each JEP and JFP in `interim/shapefiles/{train,test}_{jfp,jep}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# import geopandas as gpd\n",
    "from src.utils import read_shapefile, mask_raster\n",
    "\n",
    "from config import interim_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_ids = {'train': {'JEP': [], 'JFP': []}, 'test': {'JEP': [], 'JFP': []}}\n",
    "\n",
    "for dataset in ['train','test']:\n",
    "    shp_df = read_shapefile(dataset)\n",
    "    \n",
    "    for label in ['JEP', 'JFP']:\n",
    "\n",
    "        # Select a image\n",
    "        img_fpath = f'../data/interim/images/2017-01-01/B02_{label}.jp2'\n",
    "\n",
    "        with rasterio.open(img_fpath) as raster:\n",
    "            masks = mask_raster(shp_df.geometry, raster, return_missing=False)\n",
    "\n",
    "        farm_ids[dataset][label] = list(masks.keys())\n",
    "\n",
    "        del masks\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/interim/farm_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(farm_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put into methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_farm_ids(output_fpath):\n",
    "    \"\"\"\n",
    "    Creates a pickle dump of farm ids\n",
    "    present in datasets (train/test) and \n",
    "    labels (JEP & JFP)\n",
    "    \"\"\"\n",
    "    \n",
    "    farm_ids = {'train': {'JEP': [], 'JFP': []}, 'test': {'JEP': [], 'JFP': []}}\n",
    "    \n",
    "    for dataset in ['train','test']:\n",
    "        shp_df = read_shapefile(dataset)\n",
    "\n",
    "        for label in ['JEP', 'JFP']:\n",
    "\n",
    "            # Select an image to load\n",
    "            img_fpath = os.path.join(interim_data_dir, f'images/2017-01-01/B02_{label}.jp2')\n",
    "            \n",
    "            if not os.path.isfile(img_fpath):\n",
    "                raise FileNotFoundError('''\n",
    "                Images have not been reordered into interim data dir.\n",
    "                \\n\\nSee readme to run invoke command for re-odering image data. \n",
    "                ''')\n",
    "\n",
    "            with rasterio.open(img_fpath) as raster:\n",
    "                masks = mask_raster(shp_df.geometry, raster, return_missing=False)\n",
    "\n",
    "            farm_ids[dataset][label] = list(masks.keys())\n",
    "\n",
    "            del masks\n",
    "            gc.collect()\n",
    "    \n",
    "    with open(output_fpath, 'wb') as f:\n",
    "        pickle.dump(farm_ids, f)\n",
    "    \n",
    "    return farm_ids\n",
    "\n",
    "\n",
    "def get_farm_ids(dataset='train', label='JFP'):\n",
    "    \"\"\"\n",
    "    Gets a list of farm ids present in the \n",
    "    selected dataset and label\n",
    "    \"\"\"\n",
    "    \n",
    "    import pickle\n",
    "    from config import interim_data_dir\n",
    "    \n",
    "    ids_fpath = os.path.join(interim_data_dir, 'farm_ids.pkl')\n",
    "    \n",
    "    if not os.path.isfile(ids_fpath):\n",
    "        farm_ids = create_farm_ids(ids_fpath)\n",
    "    \n",
    "    else:\n",
    "        with open(ids_fpath, 'rb') as f:\n",
    "            farm_ids = pickle.load(f)\n",
    "    \n",
    "    return farm_ids[dataset][label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_ids = get_farm_ids(dataset='train',label='JEP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new train and test shape files for JEP and JFP dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shp = read_shapefile('train')\n",
    "test_shp = read_shapefile('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2344, 4)\n",
      "(1004, 3)\n"
     ]
    }
   ],
   "source": [
    "train_ids = get_farm_ids('train','JEP')\n",
    "train_shp_jep = train_shp.loc[train_ids]\n",
    "\n",
    "print(train_shp_jep.shape)\n",
    "\n",
    "test_ids = get_farm_ids('test','JEP')\n",
    "test_shp_jep = test_shp.loc[test_ids]\n",
    "\n",
    "print(test_shp_jep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shp_jep.to_file(os.path.join(interim_data_dir, 'shapefiles', 'train_jep'))\n",
    "test_shp_jep.to_file(os.path.join(interim_data_dir, 'shapefiles', 'test_jep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 4)\n",
      "(232, 3)\n"
     ]
    }
   ],
   "source": [
    "train_ids = get_farm_ids('train','JFP')\n",
    "train_shp_jfp = train_shp.loc[train_ids]\n",
    "\n",
    "print(train_shp_jfp.shape)\n",
    "\n",
    "test_ids = get_farm_ids('test','JFP')\n",
    "test_shp_jfp = test_shp.loc[test_ids]\n",
    "\n",
    "print(test_shp_jfp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shp_jfp.to_file(os.path.join(interim_data_dir, 'shapefiles', 'train_jfp'))\n",
    "test_shp_jfp.to_file(os.path.join(interim_data_dir, 'shapefiles', 'test_jfp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "test = gpd.read_file(os.path.join(interim_data_dir,'shapefiles','test_jep/test_jep.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Subregion</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.322590</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((614428.5851635702 6794207.23529591, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.955864</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((614617.1386412303 6794163.687688111,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.509800</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((614352.4574846183 6794416.783909474,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.477600</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((610535.7965434708 6799766.182449248,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.042300</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((610595.6245513126 6799764.027455708,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area  Subregion                                           geometry\n",
       "0   1.322590          3  POLYGON ((614428.5851635702 6794207.23529591, ...\n",
       "1   0.955864          3  POLYGON ((614617.1386412303 6794163.687688111,...\n",
       "2  11.509800          3  POLYGON ((614352.4574846183 6794416.783909474,...\n",
       "3   1.477600          3  POLYGON ((610535.7965434708 6799766.182449248,...\n",
       "4   5.042300          3  POLYGON ((610595.6245513126 6799764.027455708,..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
