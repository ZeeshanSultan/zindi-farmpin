{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create VI Dataset v8\n",
    "\n",
    "\n",
    "**Changes**\n",
    "\n",
    "`v8`:\n",
    "* Adds VIs:\n",
    "    - 'reip',\n",
    "    - 'bri',\n",
    "    - 'ipvi',\n",
    "    - 'savi',\n",
    "    - 'datt3'\n",
    "\n",
    "\n",
    "`v8.1`\n",
    "* Resample to 1month\n",
    "\n",
    "`v8.2`:\n",
    "* More stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "from tqdm import tqdm\n",
    "from config import interim_data_dir, raw_data_dir\n",
    "\n",
    "from src.utils import read_shapefile \n",
    "from src.utils import mask_raster\n",
    "\n",
    "dataset_version = \"v8.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.vi_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "def load_for_id(farm_id, dataset, bands_subset=None):\n",
    "    \"\"\"\n",
    "    Load all data for a farm\n",
    "    \n",
    "    Return:\n",
    "    \n",
    "    dictionary: {band: {date: ndarray}, {...}}\n",
    "    \"\"\"\n",
    "    farm_dir = interim_data_dir / 'masks_resampled' / dataset / str(farm_id)\n",
    "\n",
    "    dates = farm_dir.glob('*/')\n",
    "    farm_data = {}\n",
    "    \n",
    "    for date_path in dates:\n",
    "        \n",
    "        date = date_path.stem\n",
    "\n",
    "        bands = date_path.glob(\"*.npy\")\n",
    "        \n",
    "        farm_data[date_path.stem] = {}\n",
    "        \n",
    "        for band_path in bands:\n",
    "            band = band_path.stem\n",
    "            \n",
    "            if bands_subset and band not in bands_subset:\n",
    "                continue\n",
    "            else:\n",
    "                arr = np.load(band_path)\n",
    "                farm_data[date][band] = arr\n",
    "        \n",
    "    return farm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_with_clouds = ['2017-02-10','2017-08-04','2017-08-19']\n",
    "\n",
    "\n",
    "def cloud_correction(farm_data, farm_id, cloud_masks):\n",
    "    for date, cloud_mask_dict in cloud_masks.items():\n",
    "        if date not in list(farm_data.keys()):\n",
    "            raise ValueError(\"Farm {} does not have date: {}. Valid dates: {}\".format(farm_id, date, list(farm_data.keys())))\n",
    "        for band in farm_data[date].keys():\n",
    "            # replace with nan where mask is 1\n",
    "            farm_data[date][band] = np.where(cloud_mask_dict[farm_id] == 1, np.nan, farm_data[date][band])\n",
    "            \n",
    "def get_cloud_masks(shapes):\n",
    "    \"\"\"\n",
    "    Get cloud masks for all farms \n",
    "    for all dates\n",
    "    \"\"\"\n",
    "    cloud_masks = {}\n",
    "    \n",
    "    for date in dates_with_clouds:\n",
    "    \n",
    "        f_mask = interim_data_dir / 'cloud_masks' / date / 'mask_10m.jp2'\n",
    "\n",
    "        with rasterio.open(f_mask) as cloud_raster:\n",
    "            cloud_masks[date] = mask_raster(shapes, cloud_raster)\n",
    "    \n",
    "    return cloud_masks\n",
    "            \n",
    "            \n",
    "def f(farm_id, dataset, bands_subset, agg_methods, cloud_masks):\n",
    "    farm_data = load_for_id(farm_id, dataset, bands_subset=bands_subset)\n",
    "    \n",
    "    # cloud correction (in place)\n",
    "    cloud_correction(farm_data, farm_id, cloud_masks)\n",
    "\n",
    "    vi_data = [calc_vi_ts(farm_data, farm_id, agg_methods, vi_method) for vi_method in vi_methods]\n",
    "\n",
    "    vi_df = pd.concat(vi_data, axis=1)\n",
    "    \n",
    "    # interpolate missing values\n",
    "    vi_df = vi_df.sort_index(level=1).interpolate(axis=0, method='linear')\n",
    "    \n",
    "    # resample to 1 month by taking median \n",
    "    vi_df = vi_df.groupby(pd.Grouper(freq='1M', level=1)).median().interpolate()\n",
    "    \n",
    "    vi_df['farm_id'] = farm_id\n",
    "    vi_df.set_index('farm_id', append=True, inplace=True)\n",
    "\n",
    "    return vi_df\n",
    "\n",
    "\n",
    "\n",
    "def create_features_dataset_multi(dataset='train', bands_subset=None, agg_methods=['mean','median'], limit_farms=None, add_bands=True):\n",
    "    \"\"\"\n",
    "    A multi-processing solution\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    shp_df = read_shapefile(dataset)\n",
    "    \n",
    "    ids_list = shp_df.index.to_list()\n",
    "    \n",
    "    if limit_farms:\n",
    "        ids_list = ids_list[:limit_farms]\n",
    "    \n",
    "    # Get cloud masks\n",
    "    cloud_masks = get_cloud_masks(shp_df.loc[ids_list].geometry)\n",
    "        \n",
    "    partials = partial(f, dataset=dataset, bands_subset=bands_subset, agg_methods=agg_methods, cloud_masks=cloud_masks)\n",
    "        \n",
    "    pool = Pool(processes=10)\n",
    "    result = pool.map_async(partials, ids_list)\n",
    "    \n",
    "    i = 0\n",
    "    t_start = time.time()\n",
    "    while not result.ready():\n",
    "        if i == 10:\n",
    "            i=0\n",
    "            e = int(time.time() - t_start)\n",
    "            print('\\n Elapsed: {:02d}:{:02d}:{:02d}'.format(e // 3600, (e % 3600 // 60), e % 60))\n",
    "        print('.',end='')\n",
    "        i += 1\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    vi_dfs = result.get()\n",
    "    \n",
    "    df = pd.concat(vi_dfs, axis=0).reset_index()\n",
    "    \n",
    "    if dataset=='train':\n",
    "        df = df.join(shp_df[['y']], on='farm_id')\n",
    "        \n",
    "    df.time = pd.to_datetime(df.time)\n",
    "    \n",
    "    # Sort each farm by time\n",
    "    df = df.sort_values(by=['farm_id','time'])\n",
    "    \n",
    "    # After sorting the index will be jumbled, lets throw that away\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df['farm_id'] = df['farm_id'].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- Train --------------------------------------------------\n",
      "..........\n",
      " Elapsed: 00:00:05\n",
      "..........\n",
      " Elapsed: 00:00:10\n",
      "..........\n",
      " Elapsed: 00:00:15\n",
      "..........\n",
      " Elapsed: 00:00:20\n",
      "..........\n",
      " Elapsed: 00:00:25\n",
      "..........\n",
      " Elapsed: 00:00:30\n",
      "..........\n",
      " Elapsed: 00:00:35\n",
      "..........\n",
      " Elapsed: 00:00:40\n",
      "..........\n",
      " Elapsed: 00:00:45\n",
      "..........\n",
      " Elapsed: 00:00:50\n",
      "..........\n",
      " Elapsed: 00:00:55\n",
      "..........\n",
      " Elapsed: 00:01:00\n",
      "..........\n",
      " Elapsed: 00:01:05\n",
      "..........\n",
      " Elapsed: 00:01:11\n",
      "..........\n",
      " Elapsed: 00:01:16\n",
      "..........\n",
      " Elapsed: 00:01:21\n",
      "..........\n",
      " Elapsed: 00:01:26\n",
      "..........\n",
      " Elapsed: 00:01:31\n",
      "..........CPU times: user 12.6 s, sys: 4.01 s, total: 16.6 s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vi_methods = [\n",
    "    'reip',\n",
    "    'bri',\n",
    "    'ipvi',\n",
    "    'savi',\n",
    "    'ndvi',\n",
    "    'cvi',\n",
    "    'evi',\n",
    "    'arvi2',\n",
    "    'arvi',\n",
    "    'datt1',\n",
    "    'datt3',\n",
    "    'atsavi',\n",
    "    'maccioni',\n",
    "    'gari',\n",
    "    'gbndvi',\n",
    "    'mnsi',\n",
    "    'msbi',\n",
    "]\n",
    "\n",
    "\n",
    "print('-'*50,'Train','-'*50)\n",
    "\n",
    "stats = ['min','max','mean','median','std']\n",
    "\n",
    "train_features_df = create_features_dataset_multi(\n",
    "    dataset='train',\n",
    "    agg_methods=stats,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------------------------------------- Test --------------------------------------------------\n",
      "..........\n",
      " Elapsed: 00:00:05\n",
      "..........\n",
      " Elapsed: 00:00:10\n",
      "..........\n",
      " Elapsed: 00:00:15\n",
      "..........\n",
      " Elapsed: 00:00:20\n",
      "..........\n",
      " Elapsed: 00:00:25\n",
      "..........\n",
      " Elapsed: 00:00:30\n",
      "..........\n",
      " Elapsed: 00:00:35\n",
      "..........\n",
      " Elapsed: 00:00:40\n",
      "."
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print('-'*50,'Test','-'*50)\n",
    "test_features_df = create_features_dataset_multi(\n",
    "    dataset='test', \n",
    "    agg_methods=stats,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19952, 88), (8592, 87))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_df.shape, test_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot check a few known to have clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import processed_data_dir\n",
    "from src.utils import safe_create_dir\n",
    "\n",
    "out_dir = processed_data_dir / 'VI_datasets' / dataset_version\n",
    "safe_create_dir(out_dir)\n",
    "\n",
    "train_features_df.farm_id = train_features_df.farm_id.astype(str)\n",
    "test_features_df.farm_id = test_features_df.farm_id.astype(str)\n",
    "\n",
    "train_features_df.to_csv(out_dir/'train.csv')\n",
    "test_features_df.to_csv(out_dir/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
