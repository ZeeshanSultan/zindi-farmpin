{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU + Meta data DAG model \n",
    "\n",
    "\n",
    "**Sequence Data Version:** `v8.2`\n",
    "\n",
    "\n",
    "**Meta Data Version:**: `v2.1`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from config import interim_data_dir, raw_data_dir\n",
    "\n",
    "from src.utils import read_shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from config import interim_data_dir, raw_data_dir\n",
    "\n",
    "from src.utils import read_shapefile_resampled as read_shapefile\n",
    "\n",
    "from config import processed_data_dir\n",
    "\n",
    "\n",
    "# Sequential Data\n",
    "dataset_version = 'v8.2'\n",
    "\n",
    "train_features_df = pd.read_csv(processed_data_dir/'VI_datasets'/dataset_version/'train.csv', index_col=0)\n",
    "test_features_df = pd.read_csv(processed_data_dir/'VI_datasets'/dataset_version/'test.csv', index_col=0)\n",
    "\n",
    "# This is necessary for some reason\n",
    "train_features_df.farm_id = train_features_df.farm_id.astype(str)\n",
    "test_features_df.farm_id = test_features_df.farm_id.astype(str)\n",
    "\n",
    "# Meta data\n",
    "metadata_version = 'v2.1'\n",
    "train_meta_df = pd.read_csv(processed_data_dir / 'meta_data' / metadata_version / \"train_scaled.csv\", index_col=0)\n",
    "test_meta_df = pd.read_csv(processed_data_dir / 'meta_data' / metadata_version / \"test_scaled.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "\n",
    "### Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "def impute_nan_inf(df):\n",
    "    \"\"\"\n",
    "    Impute bad values (nan and inf) using\n",
    "    the median of that feature on that time stamp\n",
    "    for all farms\n",
    "    \n",
    "    TODO: This can be improved\n",
    "    \"\"\"\n",
    "    \n",
    "    # replace all nans variants with np.nan\n",
    "    df = df.replace([np.nan, None, np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # replace all nans with the median value of all farms on that timestamp\n",
    "    for ts, ts_df in df.groupby('time'):\n",
    "        df.loc[ts_df.index] = ts_df.fillna(ts_df.median())\n",
    "        \n",
    "    return df\n",
    "        \n",
    "    \n",
    "train_features_df = impute_nan_inf(train_features_df)\n",
    "test_features_df = impute_nan_inf(test_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "feature_cols = [col for col in train_features_df.columns if col not in ['farm_id','y','time']]\n",
    "\n",
    "train_scaled = train_features_df.copy()\n",
    "test_scaled = test_features_df.copy()\n",
    "\n",
    "train_scaled.loc[:, feature_cols] = scaler.fit_transform(train_features_df[feature_cols])\n",
    "test_scaled.loc[:, feature_cols] = scaler.transform(test_features_df[feature_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train / Val Split with oversampling\n",
    "\n",
    "1. Create wide-form dataset\n",
    "2. Split out val set\n",
    "3. Oversample train set\n",
    "4. Turn back into long-form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create Wide Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_cols = [c for c in train_features_df.columns.to_list() if c not in ['time','farm_id','y']]\n",
    "\n",
    "def long_to_wide(df):\n",
    "    \n",
    "    df_long = pd.pivot(df, index='farm_id', columns='time')\n",
    "    \n",
    "    columns = ['-'.join(col_pair) for col_pair in df_long.columns if 'y' not in col_pair]\n",
    "    \n",
    "    if 'y' in df:\n",
    "        \n",
    "        classes = {}\n",
    "        for farm_id, farm_group in df.groupby('farm_id'):\n",
    "            classes[farm_id] = farm_group.y.unique()[0]\n",
    "        \n",
    "        labels = pd.Series(classes, name='y')\n",
    "        \n",
    "        df_long.drop('y', axis=1, inplace=True)\n",
    "        \n",
    "        df_long = df_long.join(labels, on='farm_id')\n",
    "        \n",
    "        columns.append('y')\n",
    "        \n",
    "    df_long.columns = columns\n",
    "    \n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reip_min-2017-01-31</th>\n",
       "      <th>reip_min-2017-02-28</th>\n",
       "      <th>reip_min-2017-03-31</th>\n",
       "      <th>reip_min-2017-04-30</th>\n",
       "      <th>reip_min-2017-05-31</th>\n",
       "      <th>reip_min-2017-06-30</th>\n",
       "      <th>reip_min-2017-07-31</th>\n",
       "      <th>reip_min-2017-08-31</th>\n",
       "      <th>reip_max-2017-01-31</th>\n",
       "      <th>reip_max-2017-02-28</th>\n",
       "      <th>...</th>\n",
       "      <th>msbi_median-2017-08-31</th>\n",
       "      <th>msbi_std-2017-01-31</th>\n",
       "      <th>msbi_std-2017-02-28</th>\n",
       "      <th>msbi_std-2017-03-31</th>\n",
       "      <th>msbi_std-2017-04-30</th>\n",
       "      <th>msbi_std-2017-05-31</th>\n",
       "      <th>msbi_std-2017-06-30</th>\n",
       "      <th>msbi_std-2017-07-31</th>\n",
       "      <th>msbi_std-2017-08-31</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farm_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.568996</td>\n",
       "      <td>0.764163</td>\n",
       "      <td>0.616210</td>\n",
       "      <td>0.508593</td>\n",
       "      <td>0.400975</td>\n",
       "      <td>0.391401</td>\n",
       "      <td>0.398822</td>\n",
       "      <td>0.392872</td>\n",
       "      <td>0.301011</td>\n",
       "      <td>0.378803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667064</td>\n",
       "      <td>0.790269</td>\n",
       "      <td>0.588857</td>\n",
       "      <td>0.528198</td>\n",
       "      <td>0.467540</td>\n",
       "      <td>0.481260</td>\n",
       "      <td>0.473417</td>\n",
       "      <td>0.506413</td>\n",
       "      <td>Vineyard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.628780</td>\n",
       "      <td>0.641101</td>\n",
       "      <td>0.531394</td>\n",
       "      <td>0.447725</td>\n",
       "      <td>0.364056</td>\n",
       "      <td>0.340577</td>\n",
       "      <td>0.356648</td>\n",
       "      <td>0.327569</td>\n",
       "      <td>0.280906</td>\n",
       "      <td>0.279423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446727</td>\n",
       "      <td>0.641601</td>\n",
       "      <td>0.576854</td>\n",
       "      <td>0.534703</td>\n",
       "      <td>0.484717</td>\n",
       "      <td>0.434730</td>\n",
       "      <td>0.453058</td>\n",
       "      <td>0.470476</td>\n",
       "      <td>0.431499</td>\n",
       "      <td>Vineyard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.628569</td>\n",
       "      <td>0.657572</td>\n",
       "      <td>0.591777</td>\n",
       "      <td>0.532836</td>\n",
       "      <td>0.473895</td>\n",
       "      <td>0.397706</td>\n",
       "      <td>0.398375</td>\n",
       "      <td>0.401395</td>\n",
       "      <td>0.340499</td>\n",
       "      <td>0.327153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664277</td>\n",
       "      <td>0.588225</td>\n",
       "      <td>0.528465</td>\n",
       "      <td>0.491116</td>\n",
       "      <td>0.511710</td>\n",
       "      <td>0.532303</td>\n",
       "      <td>0.511844</td>\n",
       "      <td>0.509287</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>Vineyard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0.668922</td>\n",
       "      <td>0.720224</td>\n",
       "      <td>0.553341</td>\n",
       "      <td>0.466967</td>\n",
       "      <td>0.380594</td>\n",
       "      <td>0.394159</td>\n",
       "      <td>0.459174</td>\n",
       "      <td>0.501261</td>\n",
       "      <td>0.384975</td>\n",
       "      <td>0.465312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635944</td>\n",
       "      <td>0.649815</td>\n",
       "      <td>0.661054</td>\n",
       "      <td>0.515315</td>\n",
       "      <td>0.496043</td>\n",
       "      <td>0.476770</td>\n",
       "      <td>0.503435</td>\n",
       "      <td>0.552698</td>\n",
       "      <td>0.609662</td>\n",
       "      <td>Vineyard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>0.619985</td>\n",
       "      <td>0.752473</td>\n",
       "      <td>0.657592</td>\n",
       "      <td>0.640565</td>\n",
       "      <td>0.623539</td>\n",
       "      <td>0.637631</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0.586935</td>\n",
       "      <td>0.255279</td>\n",
       "      <td>0.490972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.644070</td>\n",
       "      <td>0.691076</td>\n",
       "      <td>0.604697</td>\n",
       "      <td>0.674534</td>\n",
       "      <td>0.744371</td>\n",
       "      <td>0.742668</td>\n",
       "      <td>0.712134</td>\n",
       "      <td>0.704241</td>\n",
       "      <td>Lucern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 681 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reip_min-2017-01-31  reip_min-2017-02-28  reip_min-2017-03-31  \\\n",
       "farm_id                                                                  \n",
       "1                   0.568996             0.764163             0.616210   \n",
       "1000                0.628780             0.641101             0.531394   \n",
       "1002                0.628569             0.657572             0.591777   \n",
       "1003                0.668922             0.720224             0.553341   \n",
       "1004                0.619985             0.752473             0.657592   \n",
       "\n",
       "         reip_min-2017-04-30  reip_min-2017-05-31  reip_min-2017-06-30  \\\n",
       "farm_id                                                                  \n",
       "1                   0.508593             0.400975             0.391401   \n",
       "1000                0.447725             0.364056             0.340577   \n",
       "1002                0.532836             0.473895             0.397706   \n",
       "1003                0.466967             0.380594             0.394159   \n",
       "1004                0.640565             0.623539             0.637631   \n",
       "\n",
       "         reip_min-2017-07-31  reip_min-2017-08-31  reip_max-2017-01-31  \\\n",
       "farm_id                                                                  \n",
       "1                   0.398822             0.392872             0.301011   \n",
       "1000                0.356648             0.327569             0.280906   \n",
       "1002                0.398375             0.401395             0.340499   \n",
       "1003                0.459174             0.501261             0.384975   \n",
       "1004                0.630049             0.586935             0.255279   \n",
       "\n",
       "         reip_max-2017-02-28  ...  msbi_median-2017-08-31  \\\n",
       "farm_id                       ...                           \n",
       "1                   0.378803  ...                0.000000   \n",
       "1000                0.279423  ...                0.446727   \n",
       "1002                0.327153  ...                0.664277   \n",
       "1003                0.465312  ...                0.635944   \n",
       "1004                0.490972  ...                0.000000   \n",
       "\n",
       "         msbi_std-2017-01-31  msbi_std-2017-02-28  msbi_std-2017-03-31  \\\n",
       "farm_id                                                                  \n",
       "1                   0.667064             0.790269             0.588857   \n",
       "1000                0.641601             0.576854             0.534703   \n",
       "1002                0.588225             0.528465             0.491116   \n",
       "1003                0.649815             0.661054             0.515315   \n",
       "1004                0.644070             0.691076             0.604697   \n",
       "\n",
       "         msbi_std-2017-04-30  msbi_std-2017-05-31  msbi_std-2017-06-30  \\\n",
       "farm_id                                                                  \n",
       "1                   0.528198             0.467540             0.481260   \n",
       "1000                0.484717             0.434730             0.453058   \n",
       "1002                0.511710             0.532303             0.511844   \n",
       "1003                0.496043             0.476770             0.503435   \n",
       "1004                0.674534             0.744371             0.742668   \n",
       "\n",
       "         msbi_std-2017-07-31  msbi_std-2017-08-31         y  \n",
       "farm_id                                                      \n",
       "1                   0.473417             0.506413  Vineyard  \n",
       "1000                0.470476             0.431499  Vineyard  \n",
       "1002                0.509287             0.566372  Vineyard  \n",
       "1003                0.552698             0.609662  Vineyard  \n",
       "1004                0.712134             0.704241    Lucern  \n",
       "\n",
       "[5 rows x 681 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make wide-form training set\n",
    "train_features_df_wide = long_to_wide(train_scaled)\n",
    "train_features_df_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add meta data\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reip_min-2017-01-31</th>\n",
       "      <th>reip_min-2017-02-28</th>\n",
       "      <th>reip_min-2017-03-31</th>\n",
       "      <th>reip_min-2017-04-30</th>\n",
       "      <th>reip_min-2017-05-31</th>\n",
       "      <th>reip_min-2017-06-30</th>\n",
       "      <th>reip_min-2017-07-31</th>\n",
       "      <th>reip_min-2017-08-31</th>\n",
       "      <th>reip_max-2017-01-31</th>\n",
       "      <th>reip_max-2017-02-28</th>\n",
       "      <th>...</th>\n",
       "      <th>Cotton</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Lucern</th>\n",
       "      <th>Maize</th>\n",
       "      <th>Pecan</th>\n",
       "      <th>Vacant</th>\n",
       "      <th>Vineyard</th>\n",
       "      <th>Vineyard &amp; Pecan (\"Intercrop\")</th>\n",
       "      <th>nn_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farm_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.568996</td>\n",
       "      <td>0.764163</td>\n",
       "      <td>0.616210</td>\n",
       "      <td>0.508593</td>\n",
       "      <td>0.400975</td>\n",
       "      <td>0.391401</td>\n",
       "      <td>0.398822</td>\n",
       "      <td>0.392872</td>\n",
       "      <td>0.301011</td>\n",
       "      <td>0.378803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990434</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.580470</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>1.226142</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>-1.102456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.628780</td>\n",
       "      <td>0.641101</td>\n",
       "      <td>0.531394</td>\n",
       "      <td>0.447725</td>\n",
       "      <td>0.364056</td>\n",
       "      <td>0.340577</td>\n",
       "      <td>0.356648</td>\n",
       "      <td>0.327569</td>\n",
       "      <td>0.280906</td>\n",
       "      <td>0.279423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412259</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>0.424872</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>2.094398</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>0.688066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>0.628569</td>\n",
       "      <td>0.657572</td>\n",
       "      <td>0.591777</td>\n",
       "      <td>0.532836</td>\n",
       "      <td>0.473895</td>\n",
       "      <td>0.397706</td>\n",
       "      <td>0.398375</td>\n",
       "      <td>0.401395</td>\n",
       "      <td>0.340499</td>\n",
       "      <td>0.327153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412259</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>1.932885</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>0.357886</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>-0.304091</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>1.225223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>0.668922</td>\n",
       "      <td>0.720224</td>\n",
       "      <td>0.553341</td>\n",
       "      <td>0.466967</td>\n",
       "      <td>0.380594</td>\n",
       "      <td>0.394159</td>\n",
       "      <td>0.459174</td>\n",
       "      <td>0.501261</td>\n",
       "      <td>0.384975</td>\n",
       "      <td>0.465312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412259</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.077799</td>\n",
       "      <td>-0.091881</td>\n",
       "      <td>2.094398</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>1.762379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>0.619985</td>\n",
       "      <td>0.752473</td>\n",
       "      <td>0.657592</td>\n",
       "      <td>0.640565</td>\n",
       "      <td>0.623539</td>\n",
       "      <td>0.637631</td>\n",
       "      <td>0.630049</td>\n",
       "      <td>0.586935</td>\n",
       "      <td>0.255279</td>\n",
       "      <td>0.490972</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412259</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>0.687167</td>\n",
       "      <td>0.927543</td>\n",
       "      <td>-0.091881</td>\n",
       "      <td>0.357886</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>-0.304091</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>1.404275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 722 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         reip_min-2017-01-31  reip_min-2017-02-28  reip_min-2017-03-31  \\\n",
       "farm_id                                                                  \n",
       "1                   0.568996             0.764163             0.616210   \n",
       "1000                0.628780             0.641101             0.531394   \n",
       "1002                0.628569             0.657572             0.591777   \n",
       "1003                0.668922             0.720224             0.553341   \n",
       "1004                0.619985             0.752473             0.657592   \n",
       "\n",
       "         reip_min-2017-04-30  reip_min-2017-05-31  reip_min-2017-06-30  \\\n",
       "farm_id                                                                  \n",
       "1                   0.508593             0.400975             0.391401   \n",
       "1000                0.447725             0.364056             0.340577   \n",
       "1002                0.532836             0.473895             0.397706   \n",
       "1003                0.466967             0.380594             0.394159   \n",
       "1004                0.640565             0.623539             0.637631   \n",
       "\n",
       "         reip_min-2017-07-31  reip_min-2017-08-31  reip_max-2017-01-31  \\\n",
       "farm_id                                                                  \n",
       "1                   0.398822             0.392872             0.301011   \n",
       "1000                0.356648             0.327569             0.280906   \n",
       "1002                0.398375             0.401395             0.340499   \n",
       "1003                0.459174             0.501261             0.384975   \n",
       "1004                0.630049             0.586935             0.255279   \n",
       "\n",
       "         reip_max-2017-02-28  ...    Cotton     Dates     Grass    Lucern  \\\n",
       "farm_id                       ...                                           \n",
       "1                   0.378803  ...  0.990434 -0.146653 -0.482659 -0.580470   \n",
       "1000                0.279423  ... -0.412259 -0.146653 -0.482659  0.424872   \n",
       "1002                0.327153  ... -0.412259 -0.146653 -0.482659  1.932885   \n",
       "1003                0.465312  ... -0.412259 -0.146653 -0.482659 -0.077799   \n",
       "1004                0.490972  ... -0.412259 -0.146653  0.687167  0.927543   \n",
       "\n",
       "            Maize     Pecan    Vacant  Vineyard  \\\n",
       "farm_id                                           \n",
       "1       -0.672012  1.226142 -0.779975  0.106967   \n",
       "1000    -0.672012  2.094398 -0.779975  0.106967   \n",
       "1002    -0.672012  0.357886 -0.779975 -0.304091   \n",
       "1003    -0.091881  2.094398 -0.779975  0.106967   \n",
       "1004    -0.091881  0.357886 -0.779975 -0.304091   \n",
       "\n",
       "         Vineyard & Pecan (\"Intercrop\")  nn_count  \n",
       "farm_id                                            \n",
       "1                              0.889687 -1.102456  \n",
       "1000                          -0.405631  0.688066  \n",
       "1002                          -0.405631  1.225223  \n",
       "1003                          -0.405631  1.762379  \n",
       "1004                          -0.405631  1.404275  \n",
       "\n",
       "[5 rows x 722 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta_df.index = train_meta_df.index.astype(str)\n",
    "\n",
    "train_wide = train_features_df_wide.join(train_meta_df, on='farm_id')\n",
    "train_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split out val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1995, 721), (499, 721))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split out val set\n",
    "X_wide = train_wide.drop('y', axis=1)\n",
    "y = train_features_df_wide.y\n",
    "\n",
    "X_train_wide, X_val_wide, y_train, y_val = train_test_split(X_wide, y, stratify=y, test_size=0.2, random_state=2019)\n",
    "\n",
    "# Save for later\n",
    "wide_col_names = X_wide.columns\n",
    "X_wide_train_index = X_train_wide.index\n",
    "\n",
    "X_train_wide.shape, X_val_wide.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Over Sample\n",
    "\n",
    "1. Random up-sample `Dates` to 10 samples\n",
    "2. Synthetically up-sample all clases below certain value (tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vineyard                          753\n",
       "Lucern                            429\n",
       "Maize                             226\n",
       "Vacant                            213\n",
       "Pecan                             117\n",
       "Cotton                            113\n",
       "Grass                              76\n",
       "Vineyard & Pecan (\"Intercrop\")     62\n",
       "Dates                              10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Up sample dates\n",
    "random = RandomOverSampler({'Dates': 10},random_state=2019)\n",
    "X_train_temp, y_train_temp = random.fit_resample(X_train_wide, y_train)\n",
    "\n",
    "pd.Series(y_train_temp).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "\n",
    "# oversample the training set\n",
    "sample = ADASYN(sampling_strategy={\n",
    "                'Grass': 150,\n",
    "                'Vineyard & Pecan (\"Intercrop\")':  100,\n",
    "                'Dates': 20,\n",
    "                'Pecan': 170,\n",
    "              }, \n",
    "              random_state=2019,\n",
    "              )\n",
    "\n",
    "X_train_wide_resampled, y_train_resampled = sample.fit_resample(X_train_temp, y_train_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vineyard                          753\n",
       "Lucern                            429\n",
       "Maize                             226\n",
       "Vacant                            213\n",
       "Pecan                             172\n",
       "Grass                             151\n",
       "Vineyard & Pecan (\"Intercrop\")    114\n",
       "Cotton                            113\n",
       "Dates                              20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turn oversampled data into DataFrame with new Farm IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reip_min-2017-01-31</th>\n",
       "      <th>reip_min-2017-02-28</th>\n",
       "      <th>reip_min-2017-03-31</th>\n",
       "      <th>reip_min-2017-04-30</th>\n",
       "      <th>reip_min-2017-05-31</th>\n",
       "      <th>reip_min-2017-06-30</th>\n",
       "      <th>reip_min-2017-07-31</th>\n",
       "      <th>reip_min-2017-08-31</th>\n",
       "      <th>reip_max-2017-01-31</th>\n",
       "      <th>reip_max-2017-02-28</th>\n",
       "      <th>...</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Lucern</th>\n",
       "      <th>Maize</th>\n",
       "      <th>Pecan</th>\n",
       "      <th>Vacant</th>\n",
       "      <th>Vineyard</th>\n",
       "      <th>Vineyard &amp; Pecan (\"Intercrop\")</th>\n",
       "      <th>nn_count</th>\n",
       "      <th>farm_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>0.565894</td>\n",
       "      <td>0.582415</td>\n",
       "      <td>0.463939</td>\n",
       "      <td>0.417350</td>\n",
       "      <td>0.370761</td>\n",
       "      <td>0.331598</td>\n",
       "      <td>0.331663</td>\n",
       "      <td>0.336163</td>\n",
       "      <td>0.278120</td>\n",
       "      <td>0.312913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-1.029045</td>\n",
       "      <td>0.881082</td>\n",
       "      <td>1.814076</td>\n",
       "      <td>-0.094386</td>\n",
       "      <td>-0.449724</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>-0.284273</td>\n",
       "      <td>os_191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>0.597281</td>\n",
       "      <td>0.682349</td>\n",
       "      <td>0.535654</td>\n",
       "      <td>0.422686</td>\n",
       "      <td>0.309719</td>\n",
       "      <td>0.293686</td>\n",
       "      <td>0.317814</td>\n",
       "      <td>0.335322</td>\n",
       "      <td>0.339243</td>\n",
       "      <td>0.448925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.077799</td>\n",
       "      <td>1.343143</td>\n",
       "      <td>-0.281854</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.215154</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>-1.224937</td>\n",
       "      <td>os_192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>0.600200</td>\n",
       "      <td>0.666263</td>\n",
       "      <td>0.593741</td>\n",
       "      <td>0.470481</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.309423</td>\n",
       "      <td>0.336948</td>\n",
       "      <td>0.382887</td>\n",
       "      <td>0.277853</td>\n",
       "      <td>0.354656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-1.083141</td>\n",
       "      <td>1.327707</td>\n",
       "      <td>0.357886</td>\n",
       "      <td>-0.567553</td>\n",
       "      <td>0.631681</td>\n",
       "      <td>-0.405631</td>\n",
       "      <td>-1.331015</td>\n",
       "      <td>os_193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>0.584943</td>\n",
       "      <td>0.673246</td>\n",
       "      <td>0.461415</td>\n",
       "      <td>0.391075</td>\n",
       "      <td>0.320734</td>\n",
       "      <td>0.306888</td>\n",
       "      <td>0.315412</td>\n",
       "      <td>0.319302</td>\n",
       "      <td>0.279747</td>\n",
       "      <td>0.341367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.199370</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>-0.510370</td>\n",
       "      <td>1.524832</td>\n",
       "      <td>-0.105262</td>\n",
       "      <td>1.871731</td>\n",
       "      <td>0.400754</td>\n",
       "      <td>os_194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>0.664368</td>\n",
       "      <td>0.722597</td>\n",
       "      <td>0.489998</td>\n",
       "      <td>0.464424</td>\n",
       "      <td>0.438850</td>\n",
       "      <td>0.390677</td>\n",
       "      <td>0.415851</td>\n",
       "      <td>0.407750</td>\n",
       "      <td>0.267652</td>\n",
       "      <td>0.371706</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.985240</td>\n",
       "      <td>-0.446036</td>\n",
       "      <td>1.587085</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>2.185004</td>\n",
       "      <td>1.055547</td>\n",
       "      <td>os_195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 722 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      reip_min-2017-01-31  reip_min-2017-02-28  reip_min-2017-03-31  \\\n",
       "2186             0.565894             0.582415             0.463939   \n",
       "2187             0.597281             0.682349             0.535654   \n",
       "2188             0.600200             0.666263             0.593741   \n",
       "2189             0.584943             0.673246             0.461415   \n",
       "2190             0.664368             0.722597             0.489998   \n",
       "\n",
       "      reip_min-2017-04-30  reip_min-2017-05-31  reip_min-2017-06-30  \\\n",
       "2186             0.417350             0.370761             0.331598   \n",
       "2187             0.422686             0.309719             0.293686   \n",
       "2188             0.470481             0.347222             0.309423   \n",
       "2189             0.391075             0.320734             0.306888   \n",
       "2190             0.464424             0.438850             0.390677   \n",
       "\n",
       "      reip_min-2017-07-31  reip_min-2017-08-31  reip_max-2017-01-31  \\\n",
       "2186             0.331663             0.336163             0.278120   \n",
       "2187             0.317814             0.335322             0.339243   \n",
       "2188             0.336948             0.382887             0.277853   \n",
       "2189             0.315412             0.319302             0.279747   \n",
       "2190             0.415851             0.407750             0.267652   \n",
       "\n",
       "      reip_max-2017-02-28  ...     Dates     Grass    Lucern     Maize  \\\n",
       "2186             0.312913  ... -0.146653 -0.482659 -1.029045  0.881082   \n",
       "2187             0.448925  ... -0.146653 -0.482659 -0.077799  1.343143   \n",
       "2188             0.354656  ... -0.146653 -0.482659 -1.083141  1.327707   \n",
       "2189             0.341367  ... -0.146653 -0.482659 -0.199370 -0.672012   \n",
       "2190             0.371706  ... -0.146653 -0.482659 -0.985240 -0.446036   \n",
       "\n",
       "         Pecan    Vacant  Vineyard  Vineyard & Pecan (\"Intercrop\")  nn_count  \\\n",
       "2186  1.814076 -0.094386 -0.449724                        0.889687 -0.284273   \n",
       "2187 -0.281854 -0.779975  0.215154                       -0.405631 -1.224937   \n",
       "2188  0.357886 -0.567553  0.631681                       -0.405631 -1.331015   \n",
       "2189 -0.510370  1.524832 -0.105262                        1.871731  0.400754   \n",
       "2190  1.587085 -0.779975  0.518026                        2.185004  1.055547   \n",
       "\n",
       "      farm_id  \n",
       "2186   os_191  \n",
       "2187   os_192  \n",
       "2188   os_193  \n",
       "2189   os_194  \n",
       "2190   os_195  \n",
       "\n",
       "[5 rows x 722 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn oversampled training set into long form\n",
    "X_train_wide = pd.DataFrame(X_train_wide_resampled, columns=wide_col_names)\n",
    "\n",
    "# Make new index\n",
    "new_train_index = pd.Index(data=list(X_wide_train_index) + [f'os_{i}' for i in range(X_train_wide.shape[0] - len(X_wide_train_index))])\n",
    "X_train_wide['farm_id'] = new_train_index\n",
    "y_train = pd.Series(y_train_resampled, index=new_train_index, name='y')\n",
    "\n",
    "X_train_wide.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. From wide back to long form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Subregion_3.0</th>\n",
       "      <th>Subregion_1.0</th>\n",
       "      <th>Subregion_4.0</th>\n",
       "      <th>Subregion_2.0</th>\n",
       "      <th>Subregion_5.0</th>\n",
       "      <th>Subregion_6.0</th>\n",
       "      <th>Subregion_0.0</th>\n",
       "      <th>Subregion_7.0</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>Cotton</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Grass</th>\n",
       "      <th>Lucern</th>\n",
       "      <th>Maize</th>\n",
       "      <th>Pecan</th>\n",
       "      <th>Vacant</th>\n",
       "      <th>Vineyard</th>\n",
       "      <th>Vineyard &amp; Pecan (\"Intercrop\")</th>\n",
       "      <th>nn_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field_Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.589766</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990434</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.58047</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>1.226142</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>-1.102456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.157671</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.761063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412259</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.58047</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>0.357886</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>1.340142</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>-0.207195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.527917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990434</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.58047</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>1.226142</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>-0.744352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.439169</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.764898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289088</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.58047</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>1.226142</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>-0.744352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.145875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.765042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412259</td>\n",
       "      <td>-0.146653</td>\n",
       "      <td>-0.482659</td>\n",
       "      <td>-0.58047</td>\n",
       "      <td>-0.672012</td>\n",
       "      <td>1.226142</td>\n",
       "      <td>-0.779975</td>\n",
       "      <td>0.929084</td>\n",
       "      <td>0.889687</td>\n",
       "      <td>-0.386247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Area  Subregion_3.0  Subregion_1.0  Subregion_4.0  \\\n",
       "Field_Id                                                          \n",
       "1        -0.589766              1              0              0   \n",
       "2        -0.157671              1              0              0   \n",
       "3        -0.527917              1              0              0   \n",
       "4        -0.439169              1              0              0   \n",
       "7         1.145875              1              0              0   \n",
       "\n",
       "          Subregion_2.0  Subregion_5.0  Subregion_6.0  Subregion_0.0  \\\n",
       "Field_Id                                                               \n",
       "1                     0              0              0              0   \n",
       "2                     0              0              0              0   \n",
       "3                     0              0              0              0   \n",
       "4                     0              0              0              0   \n",
       "7                     0              0              0              0   \n",
       "\n",
       "          Subregion_7.0       lat  ...    Cotton     Dates     Grass   Lucern  \\\n",
       "Field_Id                           ...                                          \n",
       "1                     0  1.739183  ...  0.990434 -0.146653 -0.482659 -0.58047   \n",
       "2                     0  1.761063  ... -0.412259 -0.146653 -0.482659 -0.58047   \n",
       "3                     0  1.753355  ...  0.990434 -0.146653 -0.482659 -0.58047   \n",
       "4                     0  1.764898  ...  0.289088 -0.146653 -0.482659 -0.58047   \n",
       "7                     0  1.765042  ... -0.412259 -0.146653 -0.482659 -0.58047   \n",
       "\n",
       "             Maize     Pecan    Vacant  Vineyard  \\\n",
       "Field_Id                                           \n",
       "1        -0.672012  1.226142 -0.779975  0.106967   \n",
       "2        -0.672012  0.357886 -0.779975  1.340142   \n",
       "3        -0.672012  1.226142 -0.779975  0.106967   \n",
       "4        -0.672012  1.226142 -0.779975  0.518026   \n",
       "7        -0.672012  1.226142 -0.779975  0.929084   \n",
       "\n",
       "          Vineyard & Pecan (\"Intercrop\")  nn_count  \n",
       "Field_Id                                            \n",
       "1                               0.889687 -1.102456  \n",
       "2                               0.889687 -0.207195  \n",
       "3                               0.889687 -0.744352  \n",
       "4                               0.889687 -0.744352  \n",
       "7                               0.889687 -0.386247  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the meta data again\n",
    "meta_features = train_meta_df.columns\n",
    "X_train_meta = X_train_wide[meta_features]\n",
    "X_val_meta = X_val_wide[meta_features]\n",
    "\n",
    "X_train = X_train_wide.drop(meta_features, axis=1)\n",
    "X_train = pd.wide_to_long(X_train, feature_cols, i='farm_id', j='time', sep='-',suffix='\\d+-\\d+-\\d+').sort_index(level=0)\n",
    "\n",
    "X_val = X_val_wide.drop(meta_features, axis=1)\n",
    "# Validation set wasn't touched, to just use data from after splitting\n",
    "X_val = pd.wide_to_long(X_val.reset_index(), feature_cols, i='farm_id', j='time', sep='-',suffix='\\d+-\\d+-\\d+').sort_index(level=0)\n",
    "\n",
    "# Join the labels back on\n",
    "train_features = X_train.join(y_train, on='farm_id')\n",
    "val_features = X_val.join(y_val, on='farm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = X_train.join(y_train, on='farm_id')\n",
    "val_features = X_val.join(y_val, on='farm_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Dataset for Modelling\n",
    "\n",
    "Data needs to be in the format: `(n_samples, n_time_steps, n_features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_steps = 8\n",
    "\n",
    "def transform_dataset(features_df):\n",
    "    \"\"\"\n",
    "    Create a data array in the shape (n_ids, n_time, n_features)\n",
    "    \n",
    "    If it is the training set, also return dictionary mapping index\n",
    "    in dataset to correct label.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_ids = features_df.farm_id.nunique()\n",
    "\n",
    "    feature_cols = [col for col in features_df.columns if col not in ['farm_id','y','time']]\n",
    "    \n",
    "    n_features = len(feature_cols)\n",
    "\n",
    "    data = np.ndarray((n_ids, n_time_steps, n_features))\n",
    "    \n",
    "    classes = {} # {index: label}\n",
    "    for i, (farm_id, farm_df) in enumerate(features_df.groupby(['farm_id'])):\n",
    "\n",
    "        data[i,:,:] = farm_df[feature_cols].values\n",
    "        \n",
    "        if 'y' in features_df.columns:\n",
    "            c = farm_df['y'].unique()\n",
    "            classes[i] = c[0]\n",
    "            \n",
    "    return data, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:(2191, 8, 85)\t\tMeta: (2191, 41)\n",
      "Val Data: (499, 8, 85)\t\tMeta: (499, 41)\n",
      "Test data:(1074, 8, 85)\t\tMeta: (1074, 41)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels = transform_dataset(train_features.reset_index())\n",
    "train_data_meta = X_train_meta.values\n",
    "\n",
    "val_data, val_labels = transform_dataset(val_features.reset_index())\n",
    "val_data_meta = X_val_meta.values\n",
    "\n",
    "test_data, _ = transform_dataset(test_features_df)\n",
    "test_data_meta = test_meta_df.values\n",
    "\n",
    "print('Train data:{}\\t\\tMeta: {}'.format(train_data.shape, train_data_meta.shape))\n",
    "print('Val Data: {}\\t\\tMeta: {}'.format(val_data.shape , val_data_meta.shape))\n",
    "print('Test data:{}\\t\\tMeta: {}'.format(test_data.shape, test_data_meta.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode labels to 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels_enc = le.fit_transform(np.array(list(train_labels.values())).reshape(-1,1))\n",
    "val_labels_enc = le.transform(np.array(list(val_labels.values())).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.6563213144682793,\n",
       " 3: 0.8041989958922866,\n",
       " 4: 0.896850753080785,\n",
       " 6: 0.9027841168416249,\n",
       " 5: 0.9214970333181196,\n",
       " 2: 0.9310816978548608,\n",
       " 8: 0.9479689639434048,\n",
       " 0: 0.9484253765403925,\n",
       " 1: 0.9908717480602465}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1 - pd.Series(train_labels_enc).value_counts(normalize=True)).to_dict()\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Modelling Process\n",
    "\n",
    "### Create validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from src.visualization.tf_viz import PlotLosses\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "n_time_steps = 8\n",
    "\n",
    "def get_dag_model(n_ts_features, n_meta_features):\n",
    "    \n",
    "    # Get the model\n",
    "    GRU_cells = 8\n",
    "    recurrent_activation = 'hard_sigmoid'\n",
    "    recurrent_dropout = 0.4\n",
    "    \n",
    "    dense_dropout=0.2\n",
    "\n",
    "\n",
    "    # Temporal Model\n",
    "    input_timeseries = Input(shape=(n_time_steps, n_ts_features,))\n",
    "\n",
    "    x = layers.Dense(8, activation='relu')(input_timeseries)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dense_dropout)(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dense_dropout)(x)\n",
    "    x = layers.GRU(GRU_cells, \n",
    "                         return_sequences=True,\n",
    "                         recurrent_activation=recurrent_activation, \n",
    "                         recurrent_dropout=recurrent_dropout)(x)\n",
    "    x = layers.GRU(GRU_cells, \n",
    "                         return_sequences=True,\n",
    "                         recurrent_activation=recurrent_activation, \n",
    "                         recurrent_dropout=recurrent_dropout)(x)\n",
    "#     x = layers.GRU(GRU_cells, \n",
    "#                          return_sequences=True,\n",
    "#                          recurrent_activation=recurrent_activation, \n",
    "#                          recurrent_dropout=recurrent_dropout)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dense_dropout)(x)\n",
    "\n",
    "    \n",
    "    # Meta Model\n",
    "    input_meta_data = Input(shape=(n_meta_features,))\n",
    "\n",
    "    y = layers.Dense(64, activation='relu',)(input_meta_data)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(dense_dropout)(y)\n",
    "#     y = layers.Dense(16, activation='relu')(y)\n",
    "#     y = layers.Dropout(dense_dropout)(y)\n",
    "#     y = layers.BatchNormalization()(y)\n",
    "\n",
    "    bottleneck = layers.concatenate([x,y])\n",
    "    bottleneck = layers.Dense(16, activation='relu')(bottleneck)\n",
    "    bottleneck = layers.Dropout(dense_dropout)(bottleneck)\n",
    "    bottleneck = layers.BatchNormalization()(bottleneck)\n",
    "    bottleneck = layers.Dense(9, activation='softmax')(bottleneck)\n",
    "\n",
    "    model = Model(inputs=[input_timeseries,input_meta_data], outputs=bottleneck)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set modelling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 8, 85)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 8, 8)         688         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8)         32          dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 8, 8)         0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 8, 16)        144         dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 16)        64          dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 8, 16)        0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "gru_30 (GRU)                    (None, 8, 8)         600         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gru_31 (GRU)                    (None, 8, 8)         408         gru_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 41)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 64)           0           gru_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 64)           2688        input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 64)           256         flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 64)           256         dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 64)           0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 64)           0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 128)          0           dropout_68[0][0]                 \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 16)           2064        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 16)           0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16)           64          dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 9)            153         batch_normalization_70[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 7,417\n",
      "Trainable params: 7,081\n",
      "Non-trainable params: 336\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from src.models.clr_callback import CyclicLR\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from config import models_dir\n",
    "\n",
    "plot_losses = PlotLosses()\n",
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=100)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=30, verbose=1, factor=0.5, min_delta=0.001,)\n",
    "\n",
    "f_checkpoint_val = str(models_dir / f'gru_dag_val_{dataset_version}.{metadata_version}.hdf5')\n",
    "checkpoint = ModelCheckpoint(f_checkpoint_val, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             monitor='val_loss')\n",
    "\n",
    "\n",
    "# Combine Callbacks\n",
    "callbacks = [\n",
    "    plot_losses, \n",
    "    es, \n",
    "    reduce_lr,\n",
    "    checkpoint\n",
    "]\n",
    "\n",
    "# Create model & compile\n",
    "model = get_dag_model(train_data.shape[-1], train_data_meta.shape[-1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.00015\n",
    "lr=3e-4\n",
    "\n",
    "# Choose optimizer\n",
    "# optimizer = keras.optimizers.RMSprop(lr)\n",
    "optimizer = keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epoch_size = 1000\n",
    "\n",
    "model.fit([train_data, train_data_meta], \n",
    "          train_labels_enc,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=([val_data, val_data_meta], val_labels_enc), \n",
    "          verbose=0,\n",
    "          epochs=epoch_size, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect best model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from src.visualization.visualize import print_confusion_matrix\n",
    "\n",
    "# Load best model\n",
    "best_model = load_model(str(models_dir / f'gru_dag_val_{dataset_version}.{metadata_version}.hdf5'))\n",
    "\n",
    "class_labels = pd.read_csv(raw_data_dir / 'crop_id_list.csv', index_col=0).sort_index().crop\n",
    "\n",
    "val_probs = best_model.predict([val_data, val_data_meta])\n",
    "\n",
    "val_preds = np.argmax(val_probs, axis=1)\n",
    "\n",
    "cm = confusion_matrix(val_labels_enc, val_preds)\n",
    "print_confusion_matrix(cm, class_names=class_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pd.DataFrame(classification_report(val_labels_enc, val_preds, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(val_labels_enc, val_preds, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.vstack([train_data, val_data])\n",
    "all_labels = np.array(list(train_labels_enc) + list(val_labels_enc))\n",
    "\n",
    "all_data_meta = np.vstack([train_data_meta, val_data_meta])\n",
    "\n",
    "class_weight = (1 - pd.Series(all_labels).value_counts(normalize=True)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.clr_callback import CyclicLR\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from config import models_dir\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "lr = 0.00015\n",
    "\n",
    "# Choose optimizer\n",
    "optimizer = keras.optimizers.RMSprop(lr)\n",
    "f_checkpoint = str(models_dir / f'gru_dag_{dataset_version}.{metadata_version}.hdf5')\n",
    "checkpoint = ModelCheckpoint(f_checkpoint, \n",
    "                             save_best_only=True, \n",
    "                             mode='min', \n",
    "                             monitor='loss')\n",
    "callbacks = [\n",
    "    plot_losses, \n",
    "    checkpoint\n",
    "]\n",
    "\n",
    "model = get_dag_model(all_data.shape[-1], all_data_meta.shape[-1])\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=150\n",
    "\n",
    "model.fit([all_data,all_data_meta], \n",
    "          all_labels,\n",
    "          batch_size=batch_size,\n",
    "          class_weight=class_weight,\n",
    "          verbose=0,\n",
    "          epochs=epochs, \n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(f_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sub(predictions, ids_list):\n",
    "    \n",
    "    sub_df = pd.read_csv(raw_data_dir / 'sample_submission_fixed.csv')\n",
    "\n",
    "    new_sub = sub_df.copy().set_index('field_id')\n",
    "\n",
    "    new_sub.loc[ids_list] = predictions\n",
    "    \n",
    "    return new_sub\n",
    "\n",
    "predictions = model.predict([test_data, test_meta_data])\n",
    "test_ids = sorted(list(test_features_df.farm_id.unique()))\n",
    "sub_df = make_sub(predictions, test_ids)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import subs_dir\n",
    "\n",
    "fname = 'gru_dag_data_v7.2'\n",
    "sub_df.to_csv(subs_dir / f'{fname}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(subs_dir / 'architectures' / f'{fname}.txt', 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
